{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import nltk\n",
    "from nltk.probability import FreqDist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tweets = []\n",
    "\n",
    "# replace \n",
    "with open(\"kanye.csv\", \"r+\", encoding=\"utf-8\") as raw:\n",
    "    data = csv.reader(raw, delimiter=\",\")\n",
    "    next(data) # skip header row\n",
    "    for row in data:\n",
    "        tweets.append(row[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "collection  = \" \".join(tweets)\n",
    "# change to lowercase\n",
    "collection = collection.lower()\n",
    "# strip whitespace\n",
    "collection = collection.strip()\n",
    "# tokenize for analysis\n",
    "tokenized = nltk.tokenize.word_tokenize(collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<FreqDist with 2819 samples and 12449 outcomes>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('the', 397),\n",
       " (':', 356),\n",
       " ('.', 352),\n",
       " ('i', 319),\n",
       " ('and', 297),\n",
       " ('!', 279),\n",
       " ('to', 273),\n",
       " ('https', 182),\n",
       " ('of', 164),\n",
       " ('http', 162),\n",
       " ('a', 152),\n",
       " ('my', 150),\n",
       " ('you', 147),\n",
       " ('in', 126),\n",
       " ('@', 124),\n",
       " (',', 117),\n",
       " ('for', 116),\n",
       " ('is', 112),\n",
       " ('on', 93),\n",
       " ('me', 85),\n",
       " ('that', 82),\n",
       " ('...', 80),\n",
       " ('all', 75),\n",
       " ('this', 69),\n",
       " ('so', 68),\n",
       " ('street', 65),\n",
       " ('with', 64),\n",
       " ('#', 61),\n",
       " ('was', 61),\n",
       " ('we', 59),\n",
       " ('at', 56),\n",
       " ('be', 56),\n",
       " ('have', 53),\n",
       " ('it', 52),\n",
       " ('love', 52),\n",
       " ('…', 48),\n",
       " ('people', 48),\n",
       " ('will', 47),\n",
       " ('thank', 43),\n",
       " ('one', 43),\n",
       " ('not', 43),\n",
       " ('new', 42),\n",
       " ('by', 42),\n",
       " ('just', 41),\n",
       " ('album', 41),\n",
       " ('do', 40),\n",
       " ('now', 38),\n",
       " ('like', 37),\n",
       " ('but', 36),\n",
       " ('i’m', 35)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fdist = FreqDist(tokenized)\n",
    "print(fdist)\n",
    "fdist.most_common(50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
